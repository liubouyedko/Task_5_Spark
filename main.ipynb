{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "2123faed-4660-48a8-9ae2-30fc3f138e89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in /usr/local/spark/python (3.5.0)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in /opt/conda/lib/python3.11/site-packages (from pyspark) (0.10.9.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pyspark\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import when\n",
    "from collections import namedtuple\n",
    "import re\n",
    "\n",
    "#del list\n",
    "\n",
    "class TableLoader:\n",
    "    def __init__(self, spark, table_names):\n",
    "        self.spark = spark\n",
    "        self.table_names = table_names\n",
    "        self.load_tables()\n",
    "\n",
    "    def load_tables(self):\n",
    "        for table_name in self.table_names:\n",
    "            setattr(self, table_name, (\n",
    "                self.spark.read\n",
    "                .format(\"jdbc\")\n",
    "                .option(\"driver\", \"org.postgresql.Driver\")\n",
    "                .option(\"url\", \"jdbc:postgresql://pagila:5432/postgres\")\n",
    "                .option(\"user\", \"postgres\")\n",
    "                .option(\"password\", \"123456\")\n",
    "                .option(\"dbtable\", table_name)\n",
    "                .load()\n",
    "            ))\n",
    "\n",
    "file_path = 'pagila-insert-data.sql'\n",
    "with open(file_path, 'r') as file:\n",
    "    sql_content = file.read()\n",
    "\n",
    "\n",
    "# Creating a List of tables\n",
    "pattern = re.compile(r'INSERT INTO\\s+public\\.(\\w+)', re.IGNORECASE)\n",
    "matches = pattern.findall(sql_content)\n",
    "unique_tables = sorted(set(matches))\n",
    "tables_with_duplicates = [\"payment\" if table.startswith(\"payment\") else table for table in unique_tables]\n",
    "tables = list(set(tables_with_duplicates))\n",
    "\n",
    "df = TableLoader(spark, tables)\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .config(\"spark.jars\", \"/jars/postgresql-42.7.4.jar\")\n",
    "    .appName(\"pomogi_snachala_sebe\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "f0dccc3f-d424-4ba1-b454-3f2d1b01f295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|       name|count|\n",
      "+-----------+-----+\n",
      "|      Drama|  152|\n",
      "|      Music|  152|\n",
      "|     Travel|  151|\n",
      "|    Foreign|  150|\n",
      "|      Games|  150|\n",
      "|   Children|  150|\n",
      "|     Action|  149|\n",
      "|     Sci-Fi|  149|\n",
      "|  Animation|  148|\n",
      "|     Family|  147|\n",
      "|   Classics|  147|\n",
      "|        New|  147|\n",
      "|     Sports|  145|\n",
      "|Documentary|  145|\n",
      "|     Comedy|  143|\n",
      "|     Horror|  142|\n",
      "+-----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Вывести количество фильмов в каждой категории, отсортировать по убыванию.\n",
    "\n",
    "count_films_by_category = (\n",
    "    df.category\n",
    "    .join(df.film_category, df.category.category_id == df.film_category.category_id, how=\"left\")\n",
    "    .join(df.film, df.film_category.film_id == df.film.film_id, how=\"left\")\n",
    "    .groupBy(df.category.name).count()\n",
    "    .sort(\"count\", ascending=False)\n",
    ")\n",
    "count_films_by_category.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "283a03c3-2d3d-49b4-91e0-5e628a103764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+-----------+-----+\n",
      "|actor_id|first_name|  last_name|count|\n",
      "+--------+----------+-----------+-----+\n",
      "|     107|      GINA|  DEGENERES|  753|\n",
      "|     181|   MATTHEW|     CARREY|  680|\n",
      "|     198|      MARY|     KEITEL|  675|\n",
      "|     144|    ANGELA|WITHERSPOON|  654|\n",
      "|     102|    WALTER|       TORN|  642|\n",
      "|      60|     HENRY|      BERRY|  612|\n",
      "|     150|     JAYNE|      NOLTE|  612|\n",
      "|      23|    SANDRA|     KILMER|  605|\n",
      "|      37|       VAL|     BOLGER|  605|\n",
      "|      90|      SEAN|    GUINESS|  599|\n",
      "+--------+----------+-----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Вывести 10 актеров, чьи фильмы большего всего арендовали, отсортировать по убыванию.\n",
    "\n",
    "most_rental_actors = (\n",
    "    df.actor\n",
    "    .join(df.film_actor, df.actor.actor_id == df.film_actor.actor_id, how=\"left\")\n",
    "    .join(df.film, df.film_actor.film_id == df.film.film_id, how=\"left\")\n",
    "    .join(df.inventory, df.film.film_id == df.inventory.film_id, how=\"left\")\n",
    "    .join(df.rental, df.inventory.inventory_id == df.rental.inventory_id, how=\"left\")\n",
    "    .groupBy(df.actor.actor_id, df.actor.first_name, df.actor.last_name)\n",
    "    .count()\n",
    "    .sort(\"count\", ascending=False)\n",
    "    .limit(10)\n",
    ")\n",
    "most_rental_actors.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "1f5e8ddf-8052-415c-8fc0-cf697402da49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+-----------+\n",
      "|category_id|   name|total_spent|\n",
      "+-----------+-------+-----------+\n",
      "|          9|Foreign|   10507.67|\n",
      "+-----------+-------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Вывести категорию фильмов, на которую потратили больше всего денег.\n",
    "\n",
    "most_expensive_category = (\n",
    "    df.category\n",
    "    .join(df.film_category, df.category.category_id == df.film_category.category_id, how=\"left\")\n",
    "    .join(df.film, df.film_category.film_id == df.film.film_id, how=\"left\")\n",
    "    .join(df.inventory, df.film.film_id == df.inventory.film_id, how=\"left\")\n",
    "    .join(df.rental, df.inventory.inventory_id == df.rental.inventory_id, how=\"left\")\n",
    "    .join(df.payment, df.rental.rental_id == df.payment.rental_id, how=\"left\")\n",
    "    .groupBy(df.category.category_id, df.category.name)\n",
    "    .agg(F.sum(df.payment.amount).alias(\"total_spent\"))\n",
    "    .sort(\"total_spent\", ascending=False)\n",
    "    .limit(1)\n",
    ")\n",
    "\n",
    "most_expensive_category.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "44a694e5-6c15-413b-95fb-7297443eaf19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------------------+\n",
      "|film_id|title                 |\n",
      "+-------+----------------------+\n",
      "|148    |CHOCOLATE DUCK        |\n",
      "|108    |BUTCH PANTHER         |\n",
      "|950    |VOLUME HOUSE          |\n",
      "|642    |ORDER BETRAYED        |\n",
      "|874    |TADPOLE PARK          |\n",
      "|497    |KILL BROTHERHOOD      |\n",
      "|332    |FRANKENSTEIN STRANGER |\n",
      "|192    |CROSSING DIVORCE      |\n",
      "|860    |SUICIDES SILENCE      |\n",
      "|128    |CATCH AMISTAD         |\n",
      "|671    |PERDITION FARGO       |\n",
      "|325    |FLOATS GARDEN         |\n",
      "|386    |GUMP DATE             |\n",
      "|955    |WALLS ARTIST          |\n",
      "|359    |GLADIATOR WESTWARD    |\n",
      "|419    |HOCUS FRIDA           |\n",
      "|41     |ARSENIC INDEPENDENCE  |\n",
      "|607    |MUPPET MILE           |\n",
      "|318    |FIREHOUSE VIETNAM     |\n",
      "|742    |ROOF CHAMPION         |\n",
      "|217    |DAZED PUNK            |\n",
      "|669    |PEARL DESTINY         |\n",
      "|713    |RAINBOW SHOCK         |\n",
      "|495    |KENTUCKIAN GIANT      |\n",
      "|87     |BOONDOCK BALLROOM     |\n",
      "|171    |COMMANDMENTS EXPRESS  |\n",
      "|404    |HATE HANDICAP         |\n",
      "|38     |ARK RIDGEMONT         |\n",
      "|195    |CROWDS TELEMARK       |\n",
      "|221    |DELIVERANCE MULHOLLAND|\n",
      "|712    |RAIDERS ANTITRUST     |\n",
      "|801    |SISTER FREDDY         |\n",
      "|943    |VILLAIN DESPERATE     |\n",
      "|33     |APOLLO TEEN           |\n",
      "|14     |ALICE FANTASIA        |\n",
      "|198    |CRYSTAL BREAKING      |\n",
      "|909    |TREASURE COMMAND      |\n",
      "|802    |SKY MIRACLE           |\n",
      "|144    |CHINATOWN GLADIATOR   |\n",
      "|701    |PSYCHO SHRUNK         |\n",
      "|36     |ARGONAUTS TOWN        |\n",
      "|954    |WAKE JAWS             |\n",
      "+-------+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Вывести названия фильмов, которых нет в inventory.\n",
    "\n",
    "not_in_inventory = (\n",
    "    df.film\n",
    "    .select(\"film_id\", \"title\")\n",
    "    .join(df.inventory, df.film.film_id == df.inventory.film_id, how=\"leftanti\")\n",
    ")\n",
    "\n",
    "not_in_inventory.show(not_in_inventory.count(), truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "3d9ec287-f8d6-4c56-8ebe-fb42d6b42a6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+---------+------------------------+\n",
      "|actor_id|first_name|last_name|amount_of_children_films|\n",
      "+--------+----------+---------+------------------------+\n",
      "|     105|    SIDNEY|    CROWE|                       9|\n",
      "|     139|      EWAN|  GOODING|                       9|\n",
      "|     133|   RICHARD|     PENN|                       9|\n",
      "|      87|   SPENCER|     PECK|                       8|\n",
      "|     145|       KIM|    ALLEN|                       8|\n",
      "|      66|      MARY|    TANDY|                       8|\n",
      "|      29|      ALEC|    WAYNE|                       8|\n",
      "|      56|       DAN|   HARRIS|                       8|\n",
      "|     149|   RUSSELL|   TEMPLE|                       8|\n",
      "|     181|   MATTHEW|   CARREY|                       8|\n",
      "|     131|      JANE|  JACKMAN|                       8|\n",
      "|     142|      JADA|    RYDER|                       8|\n",
      "|      84|     JAMES|     PITT|                       7|\n",
      "|     108|    WARREN|    NOLTE|                       7|\n",
      "|     123|  JULIANNE|    DENCH|                       7|\n",
      "|      34|    AUDREY|  OLIVIER|                       7|\n",
      "|      96|      GENE|   WILLIS|                       7|\n",
      "|      65|    ANGELA|   HUDSON|                       7|\n",
      "|      95|     DARYL| WAHLBERG|                       7|\n",
      "|      94|   KENNETH|     TORN|                       7|\n",
      "|      85|    MINNIE|ZELLWEGER|                       7|\n",
      "|      17|     HELEN|   VOIGHT|                       7|\n",
      "+--------+----------+---------+------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Вывести топ 3 актеров, которые больше всего появлялись в фильмах в категории “Children”. \n",
    "# Если у нескольких актеров одинаковое кол-во фильмов, вывести всех.\n",
    "\n",
    "actor_film_count = (\n",
    "    df.actor\n",
    "    .join(df.film_actor, df.actor.actor_id == df.film_actor.actor_id, how=\"left\")\n",
    "    .join(df.film, df.film_actor.film_id == df.film.film_id, how=\"left\")\n",
    "    .join(df.film_category, df.film.film_id == df.film_category.film_id, how=\"left\")\n",
    "    .join(df.category, df.film_category.category_id == df.category.category_id, how=\"left\")\n",
    "    .filter(df.category.name == \"Children\")\n",
    "    .groupBy(df.actor.actor_id, df.actor.first_name, df.actor.last_name)\n",
    "    .agg(F.count(df.category.category_id).alias(\"amount_of_children_films\"))\n",
    ")\n",
    "\n",
    "window_spec = Window.orderBy(F.col(\"amount_of_children_films\").desc())\n",
    "\n",
    "ranked_actors = (\n",
    "    actor_film_count\n",
    "    .withColumn(\"rk\", F.dense_rank().over(window_spec))\n",
    ")\n",
    "\n",
    "top_actors = ranked_actors.filter(F.col(\"rk\") <= 3)\n",
    "\n",
    "top_actors.select(\"actor_id\", \"first_name\", \"last_name\", \"amount_of_children_films\").show(top_actors.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "2512d631-421a-4ab3-a33d-e01159116b2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------------+----------------+------------------+\n",
      "|city_id|            city|active_customers|inactive_customers|\n",
      "+-------+----------------+----------------+------------------+\n",
      "|    577|         Wroclaw|               0|                 1|\n",
      "|    578|        Xiangfan|               0|                 1|\n",
      "|    111|Charlotte Amalie|               0|                 1|\n",
      "|    259|          Kamyin|               0|                 1|\n",
      "|    512|     Szkesfehrvr|               0|                 1|\n",
      "|    139|          Daxian|               0|                 1|\n",
      "|    283|      Kumbakonam|               0|                 1|\n",
      "|     57|         Bat Yam|               0|                 1|\n",
      "|    554|        Uluberia|               0|                 1|\n",
      "|    495| Southend-on-Sea|               0|                 1|\n",
      "|    356|       Najafabad|               0|                 1|\n",
      "|     24|          Amroha|               0|                 1|\n",
      "|    125|   Coatzacoalcos|               0|                 1|\n",
      "|    281|          Ktahya|               0|                 1|\n",
      "|    407|       Pingxiang|               0|                 1|\n",
      "|    148|        Duisburg|               1|                 0|\n",
      "|    463|          Sasebo|               1|                 0|\n",
      "|    471|        Shenzhen|               1|                 0|\n",
      "|    496|       Southport|               1|                 0|\n",
      "|    243|         Jodhpur|               1|                 0|\n",
      "+-------+----------------+----------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Вывести города с количеством активных и неактивных клиентов (активный — customer.active = 1). \n",
    "# Отсортировать по количеству неактивных клиентов по убыванию.\n",
    "\n",
    "city_customers = (\n",
    "    df.city\n",
    "    .join(df.address, df.city.city_id == df.address.city_id, how=\"left\")\n",
    "    .join(df.customer, df.address.address_id == df.customer.address_id, how=\"left\")\n",
    "    .groupBy(df.city.city_id, df.city.city)\n",
    "    .agg(\n",
    "        F.sum(when(df.customer.active == 1, 1).otherwise(0)).alias(\"active_customers\"),\n",
    "        F.sum(when(df.customer.active == 0, 1).otherwise(0)).alias(\"inactive_customers\")\n",
    "    )\n",
    "    .sort(\"inactive_customers\", ascending=False)\n",
    ")\n",
    "\n",
    "city_customers.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "2c974b4c-663c-49fd-bfba-0d24a301dffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------------+----------------------+\n",
      "|category_name|category_total_hours|category_type         |\n",
      "+-------------+--------------------+----------------------+\n",
      "|Children     |24427.999999999993  |City starting with 'A'|\n",
      "|Drama        |14556.033333333335  |City with '-'         |\n",
      "+-------------+--------------------+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Вывести категорию фильмов, у которой самое большое кол-во часов суммарной аренды в городах (customer.address_id в этом city), \n",
    "# и которые начинаются на букву “a”. Тоже самое сделать для городов в которых есть символ “-”.\n",
    "sec_in_hour = 3600\n",
    "\n",
    "rental_hours = (\n",
    "    df.city\n",
    "    .join(df.address, df.city.city_id == df.address.city_id, how=\"left\")\n",
    "    .join(df.customer, df.address.address_id == df.customer.address_id, how=\"left\")\n",
    "    .join(df.rental, df.customer.customer_id == df.rental.customer_id, how=\"left\")\n",
    "    .join(df.inventory, df.rental.inventory_id == df.inventory.inventory_id, how=\"left\")\n",
    "    .join(df.film, df.inventory.film_id == df.film.film_id, how=\"left\")\n",
    "    .join(df.film_category, df.film.film_id == df.film_category.film_id, how=\"left\")\n",
    "    .join(df.category, df.film_category.category_id == df.category.category_id, how=\"left\")\n",
    "    .groupBy(df.category.name.alias(\"category_name\"), df.city.city.alias(\"city_name\"))\n",
    "    .agg(F.sum((F.unix_timestamp(df.rental.return_date) - F.unix_timestamp(df.rental.rental_date)) / sec_in_hour).alias(\"total_hours\"))\n",
    ")\n",
    "\n",
    "category_hours_a = (\n",
    "    rental_hours\n",
    "    .filter(rental_hours.city_name.startswith(\"A\"))\n",
    "    .groupBy(rental_hours.category_name)\n",
    "    .agg(F.sum(rental_hours.total_hours).alias(\"category_total_hours\"))\n",
    ")\n",
    "\n",
    "category_hours_dash = (\n",
    "    rental_hours\n",
    "    .filter((rental_hours.city_name).contains(\"-\"))\n",
    "    .groupBy(rental_hours.category_name)\n",
    "    .agg(F.sum(rental_hours.total_hours).alias(\"category_total_hours\"))\n",
    ")\n",
    "\n",
    "max_category_a = (\n",
    "    category_hours_a\n",
    "    .orderBy(category_hours_a.category_total_hours.desc())\n",
    "    .limit(1)\n",
    ")\n",
    "\n",
    "max_category_dash = (\n",
    "    category_hours_dash\n",
    "    .orderBy(category_hours_dash.category_total_hours.desc())\n",
    "    .limit(1)\n",
    ")\n",
    "\n",
    "final_result = (\n",
    "    max_category_a.withColumn(\"category_type\", F.lit(\"City starting with 'A'\"))\n",
    "    .union(max_category_dash.withColumn(\"category_type\", F.lit(\"City with '-'\")))\n",
    ")\n",
    "\n",
    "final_result.show(truncate=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
